{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector Search Evaluation with Qdrant\n",
    "This notebook evaluates the performance of vector-based semantic search using Qdrant vector database and FastEmbed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install required packages for Qdrant and FastEmbed\n",
    "%pip install -q \"qdrant-client[fastembed]>=1.14.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "import uuid\n",
    "from qdrant_client import QdrantClient, models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Qdrant Connection\n",
    "Initialize connection to Qdrant vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Qdrant\n",
      "Existing collections: collections=[]\n"
     ]
    }
   ],
   "source": [
    "# Initialize Qdrant client (make sure Qdrant is running on localhost:6333 by cmd - docker run -p 6333:6333 qdrant/qdrant)\n",
    "\n",
    "client = QdrantClient(\"http://localhost:6333\")\n",
    "print(\"Connected to Qdrant\")\n",
    "print(\"Existing collections:\", client.get_collections())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "Loading documents and ground truth data for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 149 documents and 735 ground truth questions\n"
     ]
    }
   ],
   "source": [
    "# Load documents from processed JSON file\n",
    "with open('../data/processed/documents-with-ids.json', 'r') as f:\n",
    "    documents = json.load(f)\n",
    "\n",
    "# Load ground truth dataset for evaluation\n",
    "df_ground_truth = pd.read_csv('../data/processed/ground-truth-retrieval.csv')\n",
    "ground_truth = df_ground_truth.to_dict(orient='records')\n",
    "\n",
    "print(f\"Loaded {len(documents)} documents and {len(ground_truth)} ground truth questions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Vector Search Model\n",
    "Setup FastEmbed model configuration for embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using embedding model: jinaai/jina-embeddings-v2-small-en\n",
      "Embedding dimensionality: 512\n"
     ]
    }
   ],
   "source": [
    "# Configure embedding model - using FastEmbed with jinaai model\n",
    "model_name = \"jinaai/jina-embeddings-v2-small-en\"\n",
    "embedding_dimensionality = 512\n",
    "\n",
    "print(f\"Using embedding model: {model_name}\")\n",
    "print(f\"Embedding dimensionality: {embedding_dimensionality}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Qdrant Collection\n",
    "Setup vector collection for storing document embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted existing collection: vector-search-jinaai-jina-embeddings-v2-small-en\n"
     ]
    }
   ],
   "source": [
    "# Define collection name with model identifier\n",
    "collection_name = f\"vector-search-{model_name.replace('/', '-')}\"\n",
    "\n",
    "# Delete collection if it already exists (for clean evaluation)\n",
    "try:\n",
    "    client.delete_collection(collection_name=collection_name)\n",
    "    print(f\"Deleted existing collection: {collection_name}\")\n",
    "except:\n",
    "    print(f\"Collection {collection_name} does not exist, creating new one\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created collection: vector-search-jinaai-jina-embeddings-v2-small-en\n"
     ]
    }
   ],
   "source": [
    "# Create new collection with vector configuration\n",
    "client.create_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config=models.VectorParams(\n",
    "        size=embedding_dimensionality,  # Dimensionality of the vectors\n",
    "        distance=models.Distance.COSINE  # Distance metric for similarity search\n",
    "    )\n",
    ")\n",
    "\n",
    "print(f\"Created collection: {collection_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload Documents to Qdrant\n",
    "Create embeddings and store documents in the vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading documents to Qdrant with embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32fdf94d110b46de9cad2e0d902f7d6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Preparing points:   0%|          | 0/149 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e65a920a73ad4ac8a6b2525b33c535c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32e0e2147d5e4a6b8aa7906fade45f9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Adi\\Miniconda\\envs\\brahman_env\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Adi\\AppData\\Local\\Temp\\fastembed_cache\\models--xenova--jina-embeddings-v2-small-en. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93fbb5939c94431ca14feee53241a287",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/367 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a0b3327f4bd4370919087e09e5be6af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f86ce15681084b8ea92a5004e22b33ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b659a9f3d4d4a0fabd10d355e5d2fe9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "onnx/model.onnx:   0%|          | 0.00/130M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 149 documents to Qdrant collection\n"
     ]
    }
   ],
   "source": [
    "print(\"Uploading documents to Qdrant with embeddings...\")\n",
    "\n",
    "# Prepare points for upload with FastEmbed embeddings\n",
    "points = []\n",
    "for idx, doc in enumerate(tqdm(documents, desc=\"Preparing points\")):\n",
    "    point = models.PointStruct(\n",
    "        id=idx,  # Use index as point ID\n",
    "        vector=models.Document(\n",
    "            text=doc['content'], \n",
    "            model=model_name  # FastEmbed will generate embeddings automatically\n",
    "        ),\n",
    "        payload={\n",
    "            \"content\": doc['content'],\n",
    "            \"id\": doc['id'],\n",
    "            \"doc_id\": doc.get('doc_id', ''),\n",
    "            \"location\": doc.get('location', '')\n",
    "        }\n",
    "    )\n",
    "    points.append(point)\n",
    "\n",
    "# Upload points to Qdrant (FastEmbed will generate embeddings during upload)\n",
    "client.upsert(\n",
    "    collection_name=collection_name,\n",
    "    points=points\n",
    ")\n",
    "\n",
    "print(f\"Uploaded {len(points)} documents to Qdrant collection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Search Function\n",
    "Create function to perform vector search using Qdrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector search function defined\n"
     ]
    }
   ],
   "source": [
    "def qdrant_vector_search(query, limit=5):\n",
    "    \"\"\"Perform vector search using Qdrant with FastEmbed embeddings\"\"\"\n",
    "    \n",
    "    results = client.query_points(\n",
    "        collection_name=collection_name,\n",
    "        query=models.Document(\n",
    "            text=query,\n",
    "            model=model_name  # FastEmbed generates query embedding automatically\n",
    "        ),\n",
    "        limit=limit,\n",
    "        with_payload=True  # Include document metadata in results\n",
    "    )\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"Vector search function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Search Function\n",
    "Verify that the search is working correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test query: what is mysore famous for?\n",
      "Found 5 results:\n",
      "1. Score: 0.9085 | Content: Mysore painting - Mysore is famous for the Mysore style of painting that is well known for its atten...\n",
      "2. Score: 0.8687 | Content: the Kingdom of Mysore became an Indian state. The city of Mysore has so many surviving palaces that ...\n",
      "3. Score: 0.8410 | Content: In the 3rd century BCE, the region we now know as Karnataka came under the Maurya emperors of Magadh...\n",
      "4. Score: 0.8350 | Content: - the chief port city of Karnataka and second IT destination in Karnataka after Bangalore 6 Manipal ...\n",
      "5. Score: 0.8233 | Content: ruled over much of what's now Karnataka and the larger Deccan Plateau from the mid-13th to the mid-1...\n"
     ]
    }
   ],
   "source": [
    "# Test search with a sample query\n",
    "test_query = \"what is mysore famous for?\"\n",
    "test_results = qdrant_vector_search(test_query, limit=5)\n",
    "\n",
    "print(f\"Test query: {test_query}\")\n",
    "print(f\"Found {len(test_results.points)} results:\")\n",
    "for i, result in enumerate(test_results.points, 1):\n",
    "    print(f\"{i}. Score: {result.score:.4f} | Content: {result.payload['content'][:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Process\n",
    "Evaluate vector search performance using ground truth data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating vector search with Qdrant...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0eeb42d80ec841fcbafeb4f40e00ea9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating retrieval:   0%|          | 0/735 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation completed!\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluating vector search with Qdrant...\")\n",
    "\n",
    "# Initialize list to store relevance results\n",
    "relevance_total = []\n",
    "\n",
    "# Iterate through each ground truth question\n",
    "for q in tqdm(ground_truth, desc=\"Evaluating retrieval\"):\n",
    "    doc_id = q['id']  # Ground truth document ID\n",
    "    query = q['question']\n",
    "    \n",
    "    # Perform vector search using Qdrant\n",
    "    search_results = qdrant_vector_search(query, limit=5)\n",
    "    \n",
    "    # Check if correct document is in results\n",
    "    relevance = [point.payload['id'] == doc_id for point in search_results.points]\n",
    "    relevance_total.append(relevance)\n",
    "\n",
    "print(\"Evaluation completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Metrics\n",
    "Compute Hit Rate and Mean Reciprocal Rank (MRR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating metrics...\n",
      "Metrics calculated successfully!\n"
     ]
    }
   ],
   "source": [
    "print(\"Calculating metrics...\")\n",
    "\n",
    "# Calculate Hit Rate\n",
    "hit_count = sum(1 for line in relevance_total if True in line)\n",
    "hit_rate = hit_count / len(relevance_total)\n",
    "\n",
    "# Calculate Mean Reciprocal Rank (MRR)\n",
    "total_score = 0.0\n",
    "for line in relevance_total:\n",
    "    for rank in range(len(line)):\n",
    "        if line[rank] == True:\n",
    "            total_score += 1 / (rank + 1)\n",
    "            break\n",
    "\n",
    "mrr = total_score / len(relevance_total)\n",
    "\n",
    "# Create metrics dictionary\n",
    "metrics = {\n",
    "    'hit_rate': hit_rate,\n",
    "    'mrr': mrr,\n",
    "    'total_questions': len(relevance_total)\n",
    "}\n",
    "\n",
    "print(f\"Metrics calculated successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Results\n",
    "Show evaluation results before saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "VECTOR SEARCH EVALUATION RESULTS (with Qdrant)\n",
      "============================================================\n",
      "Model: jinaai/jina-embeddings-v2-small-en\n",
      "Embedding Dimensions: 512\n",
      "Collection: vector-search-jinaai-jina-embeddings-v2-small-en\n",
      "Distance Metric: COSINE\n",
      "------------------------------------------------------------\n",
      "Hit Rate: 0.5565 (409/735)\n",
      "MRR (Mean Reciprocal Rank): 0.4144\n",
      "Total Questions Evaluated: 735\n",
      "------------------------------------------------------------\n",
      "Hit Rate %: 55.65%\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Display comprehensive results\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"VECTOR SEARCH EVALUATION RESULTS (with Qdrant)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Model: {model_name}\")\n",
    "print(f\"Embedding Dimensions: {embedding_dimensionality}\")\n",
    "print(f\"Collection: {collection_name}\")\n",
    "print(f\"Distance Metric: COSINE\")\n",
    "print(\"-\"*60)\n",
    "print(f\"Hit Rate: {metrics['hit_rate']:.4f} ({hit_count}/{len(relevance_total)})\")\n",
    "print(f\"MRR (Mean Reciprocal Rank): {metrics['mrr']:.4f}\")\n",
    "print(f\"Total Questions Evaluated: {metrics['total_questions']}\")\n",
    "print(\"-\"*60)\n",
    "print(f\"Hit Rate %: {metrics['hit_rate']*100:.2f}%\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Results\n",
    "Save evaluation results to JSON file with model-specific naming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare results for saving with comprehensive information\n",
    "results = {\n",
    "    'method': 'vector_search_qdrant',\n",
    "    'model_name': model_name,\n",
    "    'model_config': {\n",
    "        'embedding_dimensions': embedding_dimensionality,\n",
    "        'distance_metric': 'COSINE',\n",
    "        'vector_database': 'Qdrant',\n",
    "        'embedding_provider': 'FastEmbed'\n",
    "    },\n",
    "    'collection_name': collection_name,\n",
    "    'metrics': metrics,\n",
    "    'relevance_results': relevance_total,\n",
    "    'evaluation_details': {\n",
    "        'total_documents': len(documents),\n",
    "        'search_limit': 5,\n",
    "        'evaluation_timestamp': pd.Timestamp.now().isoformat()\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create filename with model name for easy comparison\n",
    "model_safe_name = model_name.replace('/', '_').replace('-', '_')\n",
    "filename = f'../results/vector_search_qdrant_{model_safe_name}_results.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis Summary\n",
    "Provide insights for model comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ANALYSIS SUMMARY\n",
      "============================================================\n",
      "This evaluation used Qdrant vector database with FastEmbed\n",
      "for generating embeddings using jinaai/jina-embeddings-v2-small-en\n",
      "\n",
      "Key Insights:\n",
      "• Hit Rate of 55.6% means 409 out of 735 queries found relevant documents in top 5\n",
      "• MRR of 0.4144 indicates average rank position of first relevant result\n",
      "• Higher Hit Rate and MRR values indicate better search performance\n",
      "\n",
      "For comparison with other models:\n",
      "• Check results files in 'results/' directory\n",
      "• Compare Hit Rate and MRR values across different models\n",
      "• Consider embedding dimensions vs performance trade-offs\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ANALYSIS SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"This evaluation used Qdrant vector database with FastEmbed\")\n",
    "print(f\"for generating embeddings using {model_name}\")\n",
    "print()\n",
    "print(\"Key Insights:\")\n",
    "print(f\"• Hit Rate of {metrics['hit_rate']:.1%} means {hit_count} out of {len(relevance_total)} queries found relevant documents in top 5\")\n",
    "print(f\"• MRR of {metrics['mrr']:.4f} indicates average rank position of first relevant result\")\n",
    "print(f\"• Higher Hit Rate and MRR values indicate better search performance\")\n",
    "print()\n",
    "print(\"For comparison with other models:\")\n",
    "print(f\"• Check results files in 'results/' directory\")\n",
    "print(f\"• Compare Hit Rate and MRR values across different models\")\n",
    "print(f\"• Consider embedding dimensions vs performance trade-offs\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results saved to: ../results/vector_search_qdrant_jinaai_jina_embeddings_v2_small_en_results.json\n",
      "Collection 'vector-search-jinaai-jina-embeddings-v2-small-en' remains in Qdrant for further analysis\n"
     ]
    }
   ],
   "source": [
    "# Save results to JSON file\n",
    "with open(filename, 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(f\"\\nResults saved to: {filename}\")\n",
    "print(f\"Collection '{collection_name}' remains in Qdrant for further analysis\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brahman_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
